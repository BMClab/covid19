{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Country - Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- It's necessary a premium login to extract Segments Information, a free account doesn't have full access to all data.\n",
    ">- For this script you can use either a list of logins, or setup a unique login through the **Function** `change_user ()`, with `number_logins=1` and any login of your choice\n",
    ">- For a web scraping process is important to have a exception when the Internet connection is lost, for this was created the **Function** `connect()` that tests the connection before each Action, and a loop while in each Action too to garantee to scrap all the information\n",
    ">- Allow to download gpx file, you should create a folder to the **file1** in the **download_dir**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last update was at February, 28, 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Environment\" data-toc-modified-id=\"Environment-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Environment</a></span></li></ul></li><li><span><a href=\"#Steps-functions\" data-toc-modified-id=\"Steps-functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Steps functions</a></span></li><li><span><a href=\"#Import-activities-data\" data-toc-modified-id=\"Import-activities-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Import activities data</a></span></li><li><span><a href=\"#Create-bookmarklet\" data-toc-modified-id=\"Create-bookmarklet-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Create bookmarklet</a></span></li><li><span><a href=\"#Create-session,-open-page-and-change-language-to-English\" data-toc-modified-id=\"Create-session,-open-page-and-change-language-to-English-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Create session, open page and change language to English</a></span></li><li><span><a href=\"#Download-GPX-files\" data-toc-modified-id=\"Download-GPX-files-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Download GPX files</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:33:21.546716Z",
     "start_time": "2021-04-26T02:33:19.524321Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyversions  # https://pypi.org/project/pyversions/\n",
    "import sys, os\n",
    "import urllib.request\n",
    "import re\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import sys, os\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "import gpxpy\n",
    "import shutil\n",
    "import urllib\n",
    "pyversions.versions();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:33:21.561669Z",
     "start_time": "2021-04-26T02:33:21.550699Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "file = 'file1'\n",
    "# specify custom download directory, you should create a folder with the same name as the file in directory bellow. \n",
    "#For example: C:\\file1\n",
    "download_dir = r\"C:\"\n",
    "#It´s used a group of logins to access the Strava plataform and scraping the information\n",
    "#id_login it´s the first index to rotate logins\n",
    "id_login=0 #choose the first index in the logins list to rotate the accesses\n",
    "number_logins = 1 #choose the number of logins to use\n",
    "first_athlete=0 #variable to indicate the first position in the athletes list\n",
    "last_athlete=1 #variable to indicate the last position in the athletes list\n",
    "import_strava =\"0-1.csv\" #input list with all the athletes to scrap details informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:33:21.687211Z",
     "start_time": "2021-04-26T02:33:21.567653Z"
    }
   },
   "outputs": [],
   "source": [
    "download_dir = download_dir + '\\\\'+ file\n",
    "pd.set_option('display.float_format', lambda x: '%.4g' % x)\n",
    "options = webdriver.ChromeOptions()\n",
    "prefs = {\"download.default_directory\":download_dir+\"\\\\\",\"directory_upgrade\": True}\n",
    "options.add_experimental_option(\"prefs\", prefs)\n",
    "\n",
    "path2 = r'../Datasets'\n",
    "logins=pd.read_excel(os.path.join(path2,'logins.xlsx'))\n",
    "\n",
    "count_logins = 1\n",
    "aux_id = id_login #variable used to compare the current position of the index with the initial\n",
    "export = file+'.csv'\n",
    "\n",
    "gpx_country = []\n",
    "activity_id=[]\n",
    "athlete_id=[]\n",
    "#number of registers of countries, there is a condition, if number_info_country >= 10, stops saving the information,\n",
    "#and pass to another athlete\n",
    "number_info_country = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:33:21.717132Z",
     "start_time": "2021-04-26T02:33:21.692198Z"
    }
   },
   "outputs": [],
   "source": [
    "logins.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bellow the list of functions with their descriptions:\n",
    "\n",
    "- **open_section** - create a new instance for selenium webdriver, and load the login page\n",
    "- **login** - fill down the form and click\n",
    "- **user_access** - kill the session and starts a new one with other logins, works together with **change_user** function\n",
    "- **change_user** - this function changes the logged user if you have a list of logins. It's import to avoid 429 error (too many requests)\n",
    "- **select_english_language** - to scrap all the information in English, this function changes the language view to English\n",
    "- **go_link** - It's used to load activity page\n",
    "- **create_dataset** - organize the informations and save a **.csv** file\n",
    "- **connect** - check the Internet connection, there a loop while to wait the Internet connection\n",
    "- **page_loaded** - there is a sequence to load the page, and we can check if the activity page was loaded. The script checks if the activity page was loaded through the information of date - It was searched the number \"2\" from 2000's, and when the activity isn't found, the URL returns to homepage Strava, and we can check if exists the information \"following\", because this is a information presents only on homepage.\n",
    "\n",
    "For example: the response shows \"Activities for Nov **2**0**2**0\". There are two numbers 2, and the page is loaded. For any reason, if the activity doesn't exist anymore, so the website loads the homepage of the user. And we can check too.\n",
    "\n",
    "\n",
    "- **scraping:** athletes country are stored in this part\n",
    "- **wait_for_download_and_rename:** for each selected activity the scripts tries to download the [GPX](https://en.wikipedia.org/wiki/GPS_Exchange_Format) file, and renames each downloaded file to a specific name, given by user. This is necessary because the default name is the name of the activity. After downloading the GPX file, It was used the [gpxpy](https://pypi.org/project/gpxpy/) lib to read the gpx file, and find each latitude and longitude position to gather them, and lasting use the first position (we need only one position to find out the athletes country) as an input through [geopy](https://pypi.org/project/geopy/) lib, and waiting for the country name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:33:21.795921Z",
     "start_time": "2021-04-26T02:33:21.723123Z"
    },
    "code_folding": [
     137
    ]
   },
   "outputs": [],
   "source": [
    "from ipynb.fs.defs.webscrap_athletes import login, open_section, change_user, select_english_language,\\\n",
    "    go_link, connect\n",
    "\n",
    "#https://stackoverflow.com/questions/34548041/selenium-give-file-name-when-downloading/56570364\n",
    "# function to wait for download to finish and then rename the latest downloaded file\n",
    "def wait_for_download_and_rename(newFilename):\n",
    "    global download_dir\n",
    "    # function to wait for all chrome downloads to finish\n",
    "    def chrome_downloads(drv):\n",
    "        if not \"chrome://downloads\" in drv.current_url: # if 'chrome downloads' is not current tab\n",
    "            drv.execute_script(\"window.open('');\") # open a new tab\n",
    "            drv.switch_to.window(driver.window_handles[1]) # switch to the new tab\n",
    "            drv.get(\"chrome://downloads/\") # navigate to chrome downloads\n",
    "        return drv.execute_script(\"\"\"\n",
    "            return document.querySelector('downloads-manager')\n",
    "            .shadowRoot.querySelector('#downloadsList')\n",
    "            .items.filter(e => e.state === 'COMPLETE')\n",
    "            .map(e => e.filePath || e.file_path || e.fileUrl || e.file_url);\n",
    "            \"\"\")\n",
    "    # wait for all the downloads to be completed\n",
    "    dld_file_paths = WebDriverWait(driver, 120, 1).until(chrome_downloads) # returns list of downloaded file paths\n",
    "    # Close the current tab (chrome downloads)\n",
    "    if \"chrome://downloads\" in driver.current_url:\n",
    "        driver.close()\n",
    "    # Switch back to original tab\n",
    "    driver.switch_to.window(driver.window_handles[0]) \n",
    "    # get latest downloaded file name and path\n",
    "    dlFilename = dld_file_paths[0] # latest downloaded file from the list\n",
    "    # wait till downloaded file appears in download directory\n",
    "    time_to_wait = 20 # adjust timeout as per your needs\n",
    "    time_counter = 0\n",
    "    while not os.path.isfile(dlFilename):\n",
    "        time.sleep(1)\n",
    "        time_counter += 1\n",
    "        if time_counter > time_to_wait:\n",
    "            break\n",
    "    # rename the downloaded file\n",
    "    shutil.move(dlFilename, os.path.join(download_dir,newFilename))\n",
    "    return\n",
    "\n",
    "def page_loaded(driver,url):\n",
    "    \n",
    "    print('Page loaded?')\n",
    "    CRED = '\\033[92m'\n",
    "    CEND = '\\033[0m'\n",
    "    while True:\n",
    "        connect()\n",
    "        try:\n",
    "            #verify the activity page was loaded through the information of date - It was searched the number \"2\" from 2000's\n",
    "            loading_page = driver.find_element_by_xpath('//*[@id=\"heading\"]/div/div/div[1]/div/div/time')\n",
    "            loading_page_html=loading_page.get_attribute('innerHTML')\n",
    "            loading_page_soup=BeautifulSoup(loading_page_html, \"html.parser\")\n",
    "\n",
    "            if re.search('2',str(loading_page_soup),re.IGNORECASE):\n",
    "                print(CRED+'OKAY !!!!'+CEND)\n",
    "                break\n",
    "\n",
    "        except:\n",
    "            # Loading page\n",
    "            #when the activity isn´t found, the url returns to homepage Strava, and we can check with the information \"following\"\n",
    "            try:    \n",
    "                loading_page = driver.find_element_by_xpath('//*[@id=\"athlete-profile\"]/div[1]/ul/li[1]/a/div')\n",
    "                loading_page_html=loading_page.get_attribute('innerHTML')\n",
    "                loading_page_soup=BeautifulSoup(loading_page_html, \"html.parser\")\n",
    "\n",
    "                if re.search('Following',str(loading_page_soup),re.IGNORECASE):\n",
    "                    print(CRED+'OKAY !!!! However there is not GPX file at the page'+CEND)\n",
    "                    download = False\n",
    "                    return download\n",
    "                    break\n",
    "                else:\n",
    "                    go_link(driver,url)\n",
    "                    time.sleep(5)\n",
    "                    continue\n",
    "            \n",
    "            except: \n",
    "                go_link(driver,url)\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "                \n",
    "def download_gpx(driver,url,activity):\n",
    "    while True:\n",
    "        connect()\n",
    "        try:\n",
    "            #check if the activity page was loaded through the information of date - It was searched the number \"2\" from 2000's\n",
    "            loading_page = driver.find_element_by_xpath('//*[@id=\"selected-map\"]')\n",
    "            loading_page_html=loading_page.get_attribute('innerHTML')\n",
    "            loading_page_soup=BeautifulSoup(loading_page_html, \"html.parser\")\n",
    "            \n",
    "            #check if the map loaded trough the \"Standard map\" button\n",
    "            if re.search('standard',str(loading_page_soup),re.IGNORECASE):\n",
    "                print('Map loaded!!')\n",
    "                \n",
    "                #call bookmarklet to allow any user to catch the gpx file\n",
    "                driver.execute_script(bookmarkletCode);\n",
    "                time.sleep(5)\n",
    "                element=driver.find_element_by_xpath('//*[@id=\"mapstogpxstrava_popup_creategpx\"]')\n",
    "                driver.execute_script(\"arguments[0].click();\", element) #click\n",
    "                # call the function to wait for download to finish and rename the downloaded file\n",
    "                wait_for_download_and_rename(file+'.gpx')\n",
    "                # Parsing an existing file:\n",
    "                #gpx_file = open('D:/Dropbox/Mestrado/Estudos/Bases de estudo/Web Scraping/webscrap strava atividade/Notebooks/file1/file1.gpx', 'r',encoding='utf-8')\n",
    "                \n",
    "                gpx_file = open(re.sub('\\\\\\\\','/',download_dir)+'/'+file+'.gpx', 'r',encoding='utf-8')\n",
    "                gpx = gpxpy.parse(gpx_file)\n",
    "                coordinates = str(gpx.tracks[0].segments[0].points[0].latitude)+', '+ str(gpx.tracks[0].segments[0].points[0].longitude)\n",
    "\n",
    "                locator = Nominatim(user_agent=\"myGeocoder\")\n",
    "                location = locator.reverse(coordinates)\n",
    "\n",
    "                gpx_country.append(location.raw['address']['country'])\n",
    "                \n",
    "                activity_id.append(df_activity['activity_id'][activity])\n",
    "                athlete_id.append(df_activity['athlete_id'][activity])\n",
    "                download = True\n",
    "                \n",
    "            else:\n",
    "                download = False\n",
    "            #variable download is used to flag if download happend or not\n",
    "            return download\n",
    "            break\n",
    "                \n",
    "        except:\n",
    "            go_link(driver,url)\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "            \n",
    "def create_dataset():\n",
    "    df_activity_id=pd.DataFrame(activity_id,columns=['activity_id'])\n",
    "    df_athlete_id=pd.DataFrame(athlete_id,columns=['athlete_id'])\n",
    "    df_gpx_country=pd.DataFrame(gpx_country,columns=['country'])\n",
    "    \n",
    "    df=pd.concat([df_athlete_id,df_activity_id,df_gpx_country],axis=1)\n",
    "    \n",
    "    df.to_csv(export,index=False,sep=';')\n",
    "    print('Dataset created')\n",
    "    \n",
    "def user_access(driver,url):\n",
    "    global count_logins\n",
    "    global aux_id\n",
    "    \n",
    "    if count_logins%3==0 and number_logins>1: #check if there is more than 1 login and the number of logins up to the limit for another\n",
    "        \n",
    "        connect()\n",
    "        driver.close()\n",
    "        driver.quit()\n",
    "        \n",
    "        aux_id = aux_id + 1\n",
    "        if (aux_id - id_login)>=number_logins:\n",
    "            aux_id = id_login\n",
    "        \n",
    "        driver = open_section()\n",
    "        email, key = change_user(aux_id,logins)\n",
    "        login(driver,email, key)\n",
    "        select_english_language(driver,aux_id)\n",
    "        go_link(driver,url=url)\n",
    "        \n",
    "    \n",
    "    count_logins=count_logins+1\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import activities data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:33:21.825841Z",
     "start_time": "2021-04-26T02:33:21.797917Z"
    }
   },
   "outputs": [],
   "source": [
    "athletes_list = pd.read_csv(os.path.join(path2,import_strava),sep=';',nrows=1)\n",
    "athletes_list.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:33:21.872719Z",
     "start_time": "2021-04-26T02:33:21.831825Z"
    }
   },
   "outputs": [],
   "source": [
    "usecols = [2,7]\n",
    "athletes_list = pd.read_csv(os.path.join(path2,import_strava),sep=';',\n",
    "                            usecols=usecols,\n",
    "                            encoding='utf-8', verbose=False)\n",
    "athletes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:33:21.902636Z",
     "start_time": "2021-04-26T02:33:21.880694Z"
    }
   },
   "outputs": [],
   "source": [
    "#resample the values, to shuffle the activities\n",
    "athletes_list = athletes_list.sample(frac=1,random_state=1).reset_index(drop=True)\n",
    "unique = athletes_list.drop_duplicates(subset='athlete_id', keep='first').reset_index(drop=True)\n",
    "unique.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bookmarklet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was created a bookmarklet ([see](https://mapstogpx.com/strava/) its doc) through a javascript code. And allows to access and download the [gpx](https://en.wikipedia.org/wiki/GPS_Exchange_Format) file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:33:21.934552Z",
     "start_time": "2021-04-26T02:33:21.910616Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://mapstogpx.com/strava/\n",
    "#This code allows to use any free user to catch the gpx file\n",
    "bookmarkletURL = \"javascript:(function()%7Bfunction%20callback()%7B(function(%24)%7Bvar%20jQuery%3D%24%3Bfunction%20callback()%7BgetGpx()%7Dvar%20s%3Ddocument.createElement(%22script%22)%3Bs.src%3D%22https%3A%2F%2Fmapstogpx.com%2Fstrava%2Fmapstogpxstrava.js%22%3Bif(s.addEventListener)%7Bs.addEventListener(%22load%22%2Ccallback%2Cfalse)%7Delse%20if(s.readyState)%7Bs.onreadystatechange%3Dcallback%7Ddocument.body.appendChild(s)%3B%7D)(jQuery.noConflict(true))%7Dvar%20s%3Ddocument.createElement(%22script%22)%3Bs.src%3D%22https%3A%2F%2Fmapstogpx.com%2Fstrava%2Fjquery.min.js%22%3Bif(s.addEventListener)%7Bs.addEventListener(%22load%22%2Ccallback%2Cfalse)%7Delse%20if(s.readyState)%7Bs.onreadystatechange%3Dcallback%7Ddocument.body.appendChild(s)%3B%7D)()\"\n",
    "bookmarkletCode = bookmarkletURL.split(\"javascript:\")[1]\n",
    "bookmarkletCode = urllib.parse.unquote(bookmarkletCode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create session, open page and change language to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:33:42.958796Z",
     "start_time": "2021-04-26T02:33:21.936546Z"
    }
   },
   "outputs": [],
   "source": [
    "driver = open_section()\n",
    "email, key = change_user(id_login,logins)\n",
    "login(driver,email, key)\n",
    "select_english_language(driver,id_login)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download GPX files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:36:35.554036Z",
     "start_time": "2021-04-26T02:33:42.961789Z"
    }
   },
   "outputs": [],
   "source": [
    "for athlete in range(first_athlete,last_athlete):\n",
    "\n",
    "    #for each athlete is selected their activities\n",
    "    df_activity = athletes_list[athletes_list['athlete_id']==unique['athlete_id'][athlete]]\n",
    "    df_activity.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    for activity in range(df_activity.shape[0]):\n",
    "\n",
    "        CRED = '\\033[1m'\n",
    "        CEND = '\\033[0m'\n",
    "        print(CRED + 'Athlete - ' +str(athlete)+ \" out of \" + str(last_athlete) + \" | Activity - \" + str(activity) + \" out of \" + str(df_activity.shape[0])+ CEND)\n",
    "        \n",
    "        url = df_activity['activity_id'][activity]\n",
    "        go_link(driver,url=url)\n",
    "        driver = user_access(driver,url)\n",
    "        \n",
    "        if(page_loaded(driver,url) == False):\n",
    "            continue\n",
    "            \n",
    "        if(download_gpx(driver,url,activity)==False):\n",
    "            continue\n",
    "            \n",
    "        number_info_country += 1\n",
    "        CRED = '\\033[94m'\n",
    "        print(CRED + str(number_info_country) + ' out of 10'+CEND)\n",
    "        if number_info_country == 10:\n",
    "            number_info_country=0\n",
    "            break\n",
    "    \n",
    "    create_dataset()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.542px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
