{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Athletes - Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">- It´s necessary a premium login to extract Segments Information, a free acount doesn´t have full access to all data.\n",
    ">- For this script you can use either a list of logins, or setup a unique login through the **Function** `change_user ()`, with `number_logins=1` and any login of your choice\n",
    ">- For a web scraping process is important to have a exception when the internet connection is lost, for this was created the **Function** `connect()` that tests the connection before each Action, and a loop while in each Action too to garantee to scrap all the information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last update was at February, 18, 2021."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Setup\" data-toc-modified-id=\"Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Setup</a></span><ul class=\"toc-item\"><li><span><a href=\"#Environment\" data-toc-modified-id=\"Environment-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Environment</a></span></li></ul></li><li><span><a href=\"#Steps-functions\" data-toc-modified-id=\"Steps-functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Steps functions</a></span></li><li><span><a href=\"#Informations-to-scrap\" data-toc-modified-id=\"Informations-to-scrap-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Informations to scrap</a></span></li><li><span><a href=\"#Create-session,-open-page-and-change-language-to-English\" data-toc-modified-id=\"Create-session,-open-page-and-change-language-to-English-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Create session, open page and change language to English</a></span></li><li><span><a href=\"#Scraping\" data-toc-modified-id=\"Scraping-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Scraping</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:01:06.493383Z",
     "start_time": "2021-04-26T02:01:06.473435Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyversions  # https://pypi.org/project/pyversions/\n",
    "import sys, os\n",
    "import urllib.request\n",
    "import re\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "pyversions.versions();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:01:08.021079Z",
     "start_time": "2021-04-26T02:01:08.011107Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#parameters\n",
    "export = \"NEW YORK.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:03:06.624228Z",
     "start_time": "2021-04-26T02:03:06.554228Z"
    }
   },
   "outputs": [],
   "source": [
    "#It´s used a group of logins to access the Strava plataform and scraping the information\n",
    "#id_login it´s the first index to rotate logins\n",
    "\n",
    "path2 = r'../Datasets'\n",
    "global logins\n",
    "logins=pd.read_excel(os.path.join(path2,'logins.xlsx')) \n",
    "id_login=0 #choose the first index in the logins list to rotate the accesses\n",
    "number_logins = 1 #choose the number of logins to use\n",
    "count_logins = 1\n",
    "aux_id = id_login #variable used to compare the current position of the index with the initial\n",
    "club = 1 #1 - without attend Strava clubs, and 2 - with attend Strava clubs\n",
    "segments = 'https://www.strava.com/segments/8386468'\n",
    "\n",
    "last_page = 850 # a huge number to paginate and support the scraping process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:01:13.905815Z",
     "start_time": "2021-04-26T02:01:13.890832Z"
    }
   },
   "outputs": [],
   "source": [
    "logins.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to evaluate the page behavior, trough the DOM tree. Most of scripts were used based on their own xpath. For example: to select age_group, the scripts finds the element\n",
    "\n",
    "```sh\n",
    "element=driver.find_element_by_xpath('//*[@id=\"premium-enhanced\"]/ul/ul[1]/li['+str(ag)+']/a')\n",
    "```\n",
    "\n",
    "and selects each one with the **ag variable**.\n",
    "\n",
    "Bellow the list of functions with their descriptions:\n",
    "\n",
    "- **open_section** - create a new instance for selenium webdriver, and load the login page\n",
    "- **login** - fill down the form and click\n",
    "- **user_access** - kill the session and starts a new one with other logins, works together with **change_user\" function\n",
    "- **change_user** - this function changes the logged user if you have a list of logins. It's import to avoid 429 error (too many requests)\n",
    "- **select_english_language** - to scrap all the information in English, this function changes the language view to English\n",
    "- **go_link** - It's used to load the segments page\n",
    "- **select_gender** - for each gender selection the script fills with M for male, and F for female\n",
    "- **select_age_group** - for each age group he script selects each one through xpath\n",
    "- **next_page** - the page is selected in the footer, the **li [ ]** term needs to sum with 2 to get the next_page. For example \n",
    "\n",
    "```sh\n",
    "...ul/li['+str(page+2)+']/a')\n",
    "```\n",
    "\n",
    "if you are in page 2, the page 3 will be loaded through \n",
    "\n",
    "```\n",
    "...ul/li[4]/a')\n",
    "```\n",
    "\n",
    "There is an exception for this part: ```NoSuchElementException``` when the element isn't found, in this case when the page is the last one from the table.\n",
    "\n",
    "In the html code there is a specific area to the page selection, and each page number has a xpath that repeats after page 5. For this reason there a condition that repeats page 6 for values greater than 5.\n",
    "\n",
    ">a consequence from this: to go to page 8, you need to pass through each previous page\n",
    "\n",
    "```sh\n",
    "if page>=6:\n",
    "    page=6\n",
    "element=driver.find_element_by_xpath('//*[@id=\"results\"]/nav/ul/li['+str(page+2)+']/a')\n",
    "```\n",
    "\n",
    "- **page_loaded** - check if the page was loaded, in a negative condition, the process starts from the  current age_group selection. During this reloading process, the script doesn't store data, only after reaching the page where stopped before.\n",
    "- **scraping** - activities information are stored in this part. Personal informations as **gender** and **age group** are obtained through the for loops and selections.\n",
    "- **create_dataset** - organize the informations and save a **.csv** file\n",
    "- **connect** - check the Internet connection, there a loop while to wait the Internet connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:01:15.432889Z",
     "start_time": "2021-04-26T02:01:15.346125Z"
    },
    "code_folding": [
     0,
     11,
     61,
     73,
     82,
     94,
     115,
     137
    ]
   },
   "outputs": [],
   "source": [
    "def open_section():\n",
    "    while True:\n",
    "        try:\n",
    "            connect()\n",
    "            driver = webdriver.Chrome()\n",
    "            driver.get('https://www.strava.com/login')\n",
    "            time.sleep(5)\n",
    "            return driver\n",
    "            break\n",
    "        except: continue\n",
    "    \n",
    "def login(driver,email,key):\n",
    "    while True:\n",
    "        try:\n",
    "            connect()\n",
    "            username = driver.find_element_by_id(\"email\")\n",
    "            password = driver.find_element_by_id(\"password\")\n",
    "            username.send_keys(email)\n",
    "            password.send_keys(key)\n",
    "            driver.find_element_by_id(\"login-button\").click()\n",
    "            time.sleep(2)\n",
    "            break\n",
    "        except: \n",
    "            driver.get('https://www.strava.com/login')\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "    \n",
    "def user_access(driver,ge,ag,id_login):\n",
    "    global count_logins\n",
    "    global aux_id\n",
    "    global segments\n",
    "    \n",
    "    if count_logins%3==0 and number_logins>1: #check if there is more than 1 login and the number of logins up to the limit for another\n",
    "        \n",
    "        connect()\n",
    "        driver.close()\n",
    "        driver.quit()\n",
    "        \n",
    "        aux_id = aux_id + 1\n",
    "        if (aux_id - id_login)>=number_logins:\n",
    "            aux_id = id_login\n",
    "        \n",
    "        driver = open_section()\n",
    "        email, key = change_user(aux_id,logins)\n",
    "        login(driver,email, key)\n",
    "        select_english_language(driver,aux_id)\n",
    "        go_link(driver,url=segments)\n",
    "        select_gender(driver,ge)\n",
    "        select_age_group(driver,ag,ge)\n",
    "    \n",
    "    count_logins=count_logins+1\n",
    "    return driver\n",
    "    \n",
    "def change_user(id_login,logins):\n",
    "     \n",
    "    email = logins['email'][id_login]\n",
    "    key=logins['key'][id_login]\n",
    "    \n",
    "    \n",
    "    return email, key\n",
    "\n",
    "def select_english_language(driver,id_login):\n",
    "    while True:\n",
    "        try:\n",
    "            connect()\n",
    "            element=driver.find_element_by_xpath('//*[@id=\"language-picker\"]/ul/li[3]/div') # select English language\n",
    "            driver.execute_script(\"arguments[0].click();\", element) #click\n",
    "            break\n",
    "        except: \n",
    "            email, key = change_user(id_login,logins)\n",
    "            login(driver,email,key)\n",
    "            continue\n",
    "    \n",
    "def go_link(driver,url):\n",
    "    while True:\n",
    "        try:\n",
    "            connect()\n",
    "            driver.get(url)\n",
    "            time.sleep(2)\n",
    "            break\n",
    "        except: continue\n",
    "    \n",
    "def select_gender(driver,gender):\n",
    "    while True:\n",
    "        try:\n",
    "            connect()\n",
    "            element=driver.find_element_by_xpath('//*[@id=\"segment-results\"]/div[2]/table/tbody/tr/td[4]/div/ul/li['+str(gender)+']/a')\n",
    "            driver.execute_script(\"arguments[0].click();\", element)\n",
    "            time.sleep(1)\n",
    "            break\n",
    "        except: \n",
    "            driver.refresh()\n",
    "            continue\n",
    "    \n",
    "def select_age_group(driver,ag,ge):\n",
    "    global club\n",
    "    while True:\n",
    "        try:\n",
    "            connect()\n",
    "            #if the user attends to Strava clubs, the code below should be changed to \"ul[2]\"\n",
    "            element=driver.find_element_by_xpath('//*[@id=\"premium-enhanced\"]/ul/ul['+str(club)+']/li['+str(ag)+']/a')\n",
    "            driver.execute_script(\"arguments[0].click();\", element) \n",
    "            time.sleep(5)\n",
    "                        \n",
    "            loading_page = driver.find_element_by_xpath('//*[@id=\"segment-results\"]/div[2]/h4')\n",
    "            loading_page_html=loading_page.get_attribute('innerHTML')\n",
    "            loading_page_soup=BeautifulSoup(loading_page_html, \"html.parser\")\n",
    "            \n",
    "            if re.search(age_group[str(ag)],str(loading_page_soup),re.IGNORECASE):\n",
    "                break\n",
    "\n",
    "        except: \n",
    "            select_gender(driver,ge)\n",
    "            continue\n",
    "    \n",
    "def next_page(driver,page,ge,ag):\n",
    "    #driver.find_element_by_link_text(\"→\").click()\n",
    "    while True:\n",
    "        try:\n",
    "            connect()\n",
    "            if page>=6:\n",
    "                page=6\n",
    "            element=driver.find_element_by_xpath('//*[@id=\"results\"]/nav/ul/li['+str(page+2)+']/a')\n",
    "            element_html=element.get_attribute('innerHTML')\n",
    "            element_soup=BeautifulSoup(element_html, \"html.parser\")\n",
    "            driver.execute_script(\"arguments[0].click();\", element) \n",
    "            time.sleep(3)\n",
    "            end = False\n",
    "            \n",
    "            break\n",
    "        except NoSuchElementException:\n",
    "            if connect() == True:\n",
    "                print('End page')\n",
    "                end = True\n",
    "                break\n",
    "    return end\n",
    "            \n",
    "def page_loaded(driver,page,ge,ag,end):\n",
    "    print('Page loaded?')\n",
    "    if end == False:\n",
    "        aux_page = page\n",
    "        while True:\n",
    "            connect()\n",
    "            if page>=6:\n",
    "                page=5\n",
    "            try:\n",
    "                connect()\n",
    "                loading_page = driver.find_element_by_xpath('//*[@id=\"results\"]/nav/ul/li['+str(page+2)+']/span')\n",
    "                loading_page_html=loading_page.get_attribute('innerHTML')\n",
    "                loading_page_soup=BeautifulSoup(loading_page_html, \"html.parser\")\n",
    "\n",
    "                if str(aux_page+1) == str(loading_page_soup):\n",
    "\n",
    "                    break\n",
    "                    \n",
    "                else:\n",
    "                    select_gender(driver,ge)\n",
    "                    select_age_group(driver,ag,ge)\n",
    "                    reload_page = 1\n",
    "                    #next_page(driver,aux_page,ge,ag)\n",
    "                    aux_reload_page = reload_page\n",
    "                    while (aux_reload_page <= aux_page ):\n",
    "                        try:\n",
    "                            connect()\n",
    "                            if reload_page>=6:\n",
    "                                reload_page=6\n",
    "                            element=driver.find_element_by_xpath('//*[@id=\"results\"]/nav/ul/li['+str(reload_page+2)+']/a')\n",
    "                            driver.execute_script(\"arguments[0].click();\", element) \n",
    "                            time.sleep(3)\n",
    "                            reload_page = reload_page + 1\n",
    "                            aux_reload_page = aux_reload_page + 1\n",
    "                        except:\n",
    "                            \n",
    "                            continue\n",
    "             \n",
    "\n",
    "            except:\n",
    "                try:\n",
    "                    connect()\n",
    "                    loading_page = driver.find_element_by_xpath('//*[@id=\"results\"]/nav/ul/li['+str(page+3)+']/span')\n",
    "                    loading_page_html=loading_page.get_attribute('innerHTML')\n",
    "                    loading_page_soup=BeautifulSoup(loading_page_html, \"html.parser\")\n",
    "\n",
    "                    if str(aux_page+1) == str(loading_page_soup):\n",
    "\n",
    "                        break\n",
    "                    \n",
    "                    else:\n",
    "                        select_gender(driver,ge)\n",
    "                        select_age_group(driver,ag,ge)\n",
    "                        reload_page = 1\n",
    "                        \n",
    "                        aux_reload_page = reload_page\n",
    "                        while (aux_reload_page <= aux_page ):\n",
    "                            try:\n",
    "                                connect()\n",
    "                                if reload_page>=6:\n",
    "                                    reload_page=6\n",
    "                                element=driver.find_element_by_xpath('//*[@id=\"results\"]/nav/ul/li['+str(reload_page+2)+']/a')\n",
    "                                driver.execute_script(\"arguments[0].click();\", element) \n",
    "                                time.sleep(3)\n",
    "                                reload_page = reload_page + 1\n",
    "                                aux_reload_page = aux_reload_page + 1\n",
    "                            except:\n",
    "                                continue\n",
    "                                            \n",
    "                except:\n",
    "                    select_gender(driver,ge)\n",
    "                    select_age_group(driver,ag,ge)\n",
    "                    reload_page = 1\n",
    "                    \n",
    "                    aux_reload_page = reload_page\n",
    "                    while (aux_reload_page <= aux_page ):\n",
    "                        try:\n",
    "                            connect()\n",
    "                            if reload_page>=6:\n",
    "                                reload_page=6\n",
    "                            element=driver.find_element_by_xpath('//*[@id=\"results\"]/nav/ul/li['+str(reload_page+2)+']/a')\n",
    "                            driver.execute_script(\"arguments[0].click();\", element) \n",
    "                            time.sleep(3)\n",
    "                            reload_page = reload_page + 1\n",
    "                            aux_reload_page = aux_reload_page + 1\n",
    "                        except:\n",
    "                            continue\n",
    "                        \n",
    "                    continue\n",
    "        \n",
    "    CRED = '\\033[92m'\n",
    "    CEND = '\\033[0m'\n",
    "    print(CRED+'OKAY !!!!'+CEND)\n",
    "    \n",
    "def scraping(driver,ge,ag):\n",
    "    global results\n",
    "    global result_age_group\n",
    "    global result_gender\n",
    "    global url_activity\n",
    "    global url_athlete\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            connect()\n",
    "            information = driver.find_element_by_id(\"segment-leaderboard\")\n",
    "            html=information.get_attribute('innerHTML')\n",
    "            soup =  BeautifulSoup(html, \"html.parser\") \n",
    "            table = soup.find(\"table\", attrs={\"class\": \"table table-striped table-padded table-leaderboard\"})\n",
    "            rows = table.findAll(\"tr\")\n",
    "            break\n",
    "        except: \n",
    "            select_gender(driver,ge)\n",
    "            select_age_group(driver,ag,ge)\n",
    "            continue\n",
    "\n",
    "    print('Scraping...')\n",
    "    for row in rows:\n",
    "        try: \n",
    "            \n",
    "            a = [t.text.strip() for t in row.findAll(\"td\")][0:] \n",
    "\n",
    "            b = [c['href'] for c in row.find_all('a', href=True) if c.text] #hyperlinks\n",
    "            if len(a) == 6:\n",
    "                results.append(a)\n",
    "                \n",
    "                result_age_group.append(age_group[str(ag)])\n",
    "                result_gender.append(gender[str(ge)])\n",
    "                url_activity.append('https://strava.com' + b[1]) #b[0] athlete url | b[1] event url \n",
    "                url_athlete.append('https://strava.com' + b[0])\n",
    "\n",
    "        except:\n",
    "            next\n",
    "\n",
    "def create_dataset():\n",
    "    df_result_age_group=pd.DataFrame(result_age_group,columns=['age_group'])\n",
    "    df_result_gender=pd.DataFrame(result_gender,columns=['gender'])\n",
    "    df_url_activity=pd.DataFrame(url_activity,columns=['url_activity'])\n",
    "    df_url_athlete = pd.DataFrame(url_athlete,columns=['url_athlete'])\n",
    "\n",
    "    columns = ['classification','name', 'date','pace', 'heart_rate','time']\n",
    "    df=pd.DataFrame(results,columns=columns)\n",
    "\n",
    "\n",
    "    df=pd.concat([df,df_result_age_group,df_result_gender,df_url_activity,df_url_athlete],axis=1)\n",
    "    \n",
    "    df['major'] = df['date'].apply(lambda x: export[:-4] +' '+ str(datetime.datetime.strptime(x, '%b %d, %Y').year))\n",
    "    \n",
    "    df.to_csv(export,index=False,sep=';')\n",
    "    print('Dataset created')\n",
    "    \n",
    "def connect():\n",
    "    CRED = '\\033[91m'\n",
    "    CEND = '\\033[0m'\n",
    "    while True:\n",
    "\n",
    "        try:\n",
    "            urllib.request.urlopen('https://outlook.live.com/owa/') #Python 3.x\n",
    "            return True\n",
    "            break\n",
    "        except:\n",
    "            time.sleep(5)\n",
    "            print(CRED+'Lost connection'+CEND)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Informations to scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:01:16.720737Z",
     "start_time": "2021-04-26T02:01:16.704781Z"
    },
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "result_age_group = []\n",
    "result_gender=[]\n",
    "url_activity = []\n",
    "url_athlete = []\n",
    "age_group={'2':'19 and under','3':'20 to 24','4':'25 to 34','5':'35 to 44','6':'45 to 54','7':'55 to 64','8':'65 to 69',\n",
    "              '9':'70 to 74','10':'75+'}\n",
    "gender={'2':'M','3':'F'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create session, open page and change language to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T02:03:44.074395Z",
     "start_time": "2021-04-26T02:03:19.129592Z"
    }
   },
   "outputs": [],
   "source": [
    "driver = open_section()\n",
    "email, key = change_user(id_login,logins)\n",
    "login(driver,email, key)\n",
    "select_english_language(driver,id_login)\n",
    "go_link(driver,url=segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-04-26T02:03:20.617Z"
    },
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "for ge in range(2,4): #'2':'M','3':'F'\n",
    "    \n",
    "    for ag in range(2,11): # '2':'19 and under','3':'20 to 24','4':'25 to 34','5':'35 to 44','6':'45 to 54','7':'55 to 64','8':'65 to 69',\n",
    "                                  #'9':'70 to 74','10':'75+'        \n",
    "        select_gender(driver,ge)\n",
    "        select_age_group(driver,ag,ge)\n",
    "\n",
    "        for page in range(1,last_page):\n",
    "            \n",
    "            CRED = '\\033[1m'\n",
    "            CEND = '\\033[0m'\n",
    "\n",
    "            print(CRED + gender[str(ge)] + \" - \" + age_group[str(ag)] + \" - page - \" + str(page) + CEND)\n",
    "\n",
    "            scraping(driver,ge,ag)\n",
    "            driver = user_access(driver,ge,ag,id_login)\n",
    "\n",
    "            end = next_page(driver,page,ge,ag)\n",
    "            page_loaded(driver,page,ge,ag,end)\n",
    "            if end == True:\n",
    "                break\n",
    "        create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "277.778px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "875.99px",
    "left": "1666.3px",
    "right": "20px",
    "top": "120.885px",
    "width": "449.757px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
